#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆå¯è§†åŒ–è„šæœ¬ - åŸºäºsimplifyå®éªŒç»“æœ
é‡ç‚¹ä½¿ç”¨è¡¨æ ¼å’Œæ¸…æ™°çš„å›¾è¡¨å±•ç¤º
"""

import json
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from pathlib import Path

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

def load_fast_results():
    """åŠ è½½simplifyå®éªŒç»“æœ"""
    with open('simplyfied/results/fast_all_results.json', 'r') as f:
        return json.load(f)

def create_comparison_table():
    """åˆ›å»ºæ ‡å‡†å¯¹æ¯”è¡¨æ ¼"""
    results = load_fast_results()
    
    # åˆ›å»ºå¯¹æ¯”æ•°æ®
    comparison_data = {
        'æ¨¡å‹': ['æ ‡å‡†VGG', 'BatchNorm VGG'],
        'æµ‹è¯•å‡†ç¡®ç‡(%)': [
            f"{results['standard_comparison']['standard_vgg']['test_accuracy']:.2f}",
            f"{results['standard_comparison']['batchnorm_vgg']['test_accuracy']:.2f}"
        ],
        'æœ€ä½³éªŒè¯å‡†ç¡®ç‡(%)': [
            f"{results['standard_comparison']['standard_vgg']['best_val_acc']:.2f}",
            f"{results['standard_comparison']['batchnorm_vgg']['best_val_acc']:.2f}"
        ],
        'è®­ç»ƒæ—¶é—´(ç§’)': [
            f"{results['standard_comparison']['standard_vgg']['training_time']:.2f}",
            f"{results['standard_comparison']['batchnorm_vgg']['training_time']:.2f}"
        ]
    }
    
    df = pd.DataFrame(comparison_data)
    
    # åˆ›å»ºè¡¨æ ¼å›¾
    fig, ax = plt.subplots(figsize=(10, 4))
    ax.axis('tight')
    ax.axis('off')
    
    table = ax.table(cellText=df.values, colLabels=df.columns,
                    cellLoc='center', loc='center')
    table.auto_set_font_size(False)
    table.set_fontsize(12)
    table.scale(1.2, 1.5)
    
    # è®¾ç½®è¡¨æ ¼æ ·å¼
    for i in range(len(df.columns)):
        table[(0, i)].set_facecolor('#4CAF50')
        table[(0, i)].set_text_props(weight='bold', color='white')
    
    plt.title('VGG vs BatchNorm VGG æ€§èƒ½å¯¹æ¯”', fontsize=16, fontweight='bold', pad=20)
    plt.savefig('results/enhanced_comparison_table.png', dpi=300, bbox_inches='tight')
    plt.close()

def create_activation_comparison():
    """åˆ›å»ºæ¿€æ´»å‡½æ•°å¯¹æ¯”å›¾è¡¨"""
    results = load_fast_results()
    activations = results['activation_experiments']
    
    # å‡†å¤‡æ•°æ®
    names = list(activations.keys())
    test_accs = [activations[name]['test_accuracy'] for name in names]
    val_accs = [activations[name]['best_val_acc'] for name in names]
    
    # åˆ›å»ºå¯¹æ¯”å›¾
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # æŸ±çŠ¶å›¾
    x = np.arange(len(names))
    width = 0.35
    
    bars1 = ax1.bar(x - width/2, test_accs, width, label='æµ‹è¯•å‡†ç¡®ç‡', color='#2196F3')
    bars2 = ax1.bar(x + width/2, val_accs, width, label='éªŒè¯å‡†ç¡®ç‡', color='#FF9800')
    
    ax1.set_xlabel('æ¿€æ´»å‡½æ•°')
    ax1.set_ylabel('å‡†ç¡®ç‡ (%)')
    ax1.set_title('ä¸åŒæ¿€æ´»å‡½æ•°æ€§èƒ½å¯¹æ¯”')
    ax1.set_xticks(x)
    ax1.set_xticklabels([name.upper() for name in names])
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar in bars1:
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.5,
                f'{height:.1f}%', ha='center', va='bottom')
    
    # è¡¨æ ¼å½¢å¼
    table_data = {
        'æ¿€æ´»å‡½æ•°': [name.upper() for name in names],
        'æµ‹è¯•å‡†ç¡®ç‡(%)': [f'{acc:.2f}' for acc in test_accs],
        'éªŒè¯å‡†ç¡®ç‡(%)': [f'{acc:.2f}' for acc in val_accs],
        'æ’å': [1, 2, 4, 3]  # åŸºäºæµ‹è¯•å‡†ç¡®ç‡æ’å
    }
    
    df = pd.DataFrame(table_data)
    df = df.sort_values('æµ‹è¯•å‡†ç¡®ç‡(%)', ascending=False)
    
    ax2.axis('tight')
    ax2.axis('off')
    
    table = ax2.table(cellText=df.values, colLabels=df.columns,
                     cellLoc='center', loc='center')
    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(1, 1.5)
    
    # çªå‡ºæ˜¾ç¤ºæœ€ä½³ç»“æœ
    table[(1, 0)].set_facecolor('#4CAF50')
    table[(1, 1)].set_facecolor('#4CAF50')
    table[(1, 2)].set_facecolor('#4CAF50')
    
    ax2.set_title('æ¿€æ´»å‡½æ•°æ€§èƒ½æ’åè¡¨')
    
    plt.tight_layout()
    plt.savefig('results/enhanced_activation_comparison.png', dpi=300, bbox_inches='tight')
    plt.close()

def create_optimizer_comparison():
    """åˆ›å»ºä¼˜åŒ–å™¨å¯¹æ¯”å›¾è¡¨"""
    results = load_fast_results()
    optimizers = results['optimizer_experiments']
    
    # å‡†å¤‡æ•°æ®
    names = list(optimizers.keys())
    test_accs = [optimizers[name]['test_accuracy'] for name in names]
    training_times = [optimizers[name]['training_time'] for name in names]
    
    # åˆ›å»ºç»¼åˆå¯¹æ¯”å›¾
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
    
    # 1. å‡†ç¡®ç‡å¯¹æ¯”
    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']
    bars = ax1.bar(names, test_accs, color=colors)
    ax1.set_title('ä¼˜åŒ–å™¨æµ‹è¯•å‡†ç¡®ç‡å¯¹æ¯”')
    ax1.set_ylabel('æµ‹è¯•å‡†ç¡®ç‡ (%)')
    ax1.grid(True, alpha=0.3)
    
    for bar, acc in zip(bars, test_accs):
        ax1.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.5,
                f'{acc:.1f}%', ha='center', va='bottom')
    
    # 2. è®­ç»ƒæ—¶é—´å¯¹æ¯”
    ax2.bar(names, training_times, color=colors)
    ax2.set_title('ä¼˜åŒ–å™¨è®­ç»ƒæ—¶é—´å¯¹æ¯”')
    ax2.set_ylabel('è®­ç»ƒæ—¶é—´ (ç§’)')
    ax2.grid(True, alpha=0.3)
    
    # 3. æ•ˆç‡æ•£ç‚¹å›¾
    ax3.scatter(training_times, test_accs, c=colors, s=100, alpha=0.7)
    for i, name in enumerate(names):
        ax3.annotate(name.upper(), (training_times[i], test_accs[i]),
                    xytext=(5, 5), textcoords='offset points')
    ax3.set_xlabel('è®­ç»ƒæ—¶é—´ (ç§’)')
    ax3.set_ylabel('æµ‹è¯•å‡†ç¡®ç‡ (%)')
    ax3.set_title('ä¼˜åŒ–å™¨æ•ˆç‡åˆ†æ')
    ax3.grid(True, alpha=0.3)
    
    # 4. ç»¼åˆæ’åè¡¨
    table_data = {
        'ä¼˜åŒ–å™¨': [name.upper() for name in names],
        'æµ‹è¯•å‡†ç¡®ç‡(%)': [f'{acc:.2f}' for acc in test_accs],
        'è®­ç»ƒæ—¶é—´(ç§’)': [f'{time:.2f}' for time in training_times],
        'ç»¼åˆè¯„åˆ†': [f'{acc/max(test_accs)*0.7 + (max(training_times)-time)/max(training_times)*0.3:.2f}' 
                   for acc, time in zip(test_accs, training_times)]
    }
    
    df = pd.DataFrame(table_data)
    df = df.sort_values('æµ‹è¯•å‡†ç¡®ç‡(%)', ascending=False)
    
    ax4.axis('tight')
    ax4.axis('off')
    
    table = ax4.table(cellText=df.values, colLabels=df.columns,
                     cellLoc='center', loc='center')
    table.auto_set_font_size(False)
    table.set_fontsize(9)
    table.scale(1, 1.5)
    
    ax4.set_title('ä¼˜åŒ–å™¨ç»¼åˆæ’å')
    
    plt.tight_layout()
    plt.savefig('results/enhanced_optimizer_comparison.png', dpi=300, bbox_inches='tight')
    plt.close()

def create_learning_rate_analysis():
    """åˆ›å»ºå­¦ä¹ ç‡æ•æ„Ÿæ€§åˆ†æ"""
    results = load_fast_results()
    lr_results = results['learning_rate_experiments']
    
    # å‡†å¤‡æ•°æ®
    lrs = ['0.0001', '0.0005', '0.001', '0.002', '0.005']
    standard_accs = [lr_results['standard'][lr]['test_accuracy'] for lr in lrs]
    batchnorm_accs = [lr_results['batchnorm'][lr]['test_accuracy'] for lr in lrs]
    
    # åˆ›å»ºå¯¹æ¯”å›¾
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # 1. å­¦ä¹ ç‡æ›²çº¿
    lr_values = [float(lr) for lr in lrs]
    ax1.plot(lr_values, standard_accs, 'o-', label='æ ‡å‡†VGG', linewidth=2, markersize=8)
    ax1.plot(lr_values, batchnorm_accs, 's-', label='BatchNorm VGG', linewidth=2, markersize=8)
    ax1.set_xscale('log')
    ax1.set_xlabel('å­¦ä¹ ç‡')
    ax1.set_ylabel('æµ‹è¯•å‡†ç¡®ç‡ (%)')
    ax1.set_title('å­¦ä¹ ç‡æ•æ„Ÿæ€§åˆ†æ')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. è¯¦ç»†å¯¹æ¯”è¡¨
    table_data = {
        'å­¦ä¹ ç‡': lrs,
        'æ ‡å‡†VGG(%)': [f'{acc:.2f}' for acc in standard_accs],
        'BatchNorm VGG(%)': [f'{acc:.2f}' for acc in batchnorm_accs],
        'æ€§èƒ½æå‡(%)': [f'{bn_acc - std_acc:.2f}' for std_acc, bn_acc in zip(standard_accs, batchnorm_accs)]
    }
    
    df = pd.DataFrame(table_data)
    
    ax2.axis('tight')
    ax2.axis('off')
    
    table = ax2.table(cellText=df.values, colLabels=df.columns,
                     cellLoc='center', loc='center')
    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(1, 1.8)
    
    # çªå‡ºæ˜¾ç¤ºæœ€ä½³å­¦ä¹ ç‡
    best_std_idx = standard_accs.index(max(standard_accs)) + 1
    best_bn_idx = batchnorm_accs.index(max(batchnorm_accs)) + 1
    
    table[(best_std_idx, 1)].set_facecolor('#FFE082')
    table[(best_bn_idx, 2)].set_facecolor('#A5D6A7')
    
    ax2.set_title('å­¦ä¹ ç‡è¯¦ç»†å¯¹æ¯”è¡¨')
    
    plt.tight_layout()
    plt.savefig('results/enhanced_learning_rate_analysis.png', dpi=300, bbox_inches='tight')
    plt.close()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¨ ç”Ÿæˆå¢å¼ºç‰ˆå¯è§†åŒ–å›¾è¡¨...")
    
    # ç¡®ä¿ç»“æœç›®å½•å­˜åœ¨
    Path('results').mkdir(exist_ok=True)
    
    # ç”Ÿæˆæ‰€æœ‰å›¾è¡¨
    create_comparison_table()
    print("âœ… æ ‡å‡†å¯¹æ¯”è¡¨æ ¼å·²ç”Ÿæˆ")
    
    create_activation_comparison()
    print("âœ… æ¿€æ´»å‡½æ•°å¯¹æ¯”å›¾è¡¨å·²ç”Ÿæˆ")
    
    create_optimizer_comparison()
    print("âœ… ä¼˜åŒ–å™¨å¯¹æ¯”å›¾è¡¨å·²ç”Ÿæˆ")
    
    create_learning_rate_analysis()
    print("âœ… å­¦ä¹ ç‡åˆ†æå›¾è¡¨å·²ç”Ÿæˆ")
    
    print("\nğŸ‰ æ‰€æœ‰å¢å¼ºç‰ˆå¯è§†åŒ–å›¾è¡¨ç”Ÿæˆå®Œæˆï¼")
    print("ğŸ“ å›¾è¡¨ä¿å­˜ä½ç½®: results/enhanced_*.png")

if __name__ == "__main__":
    main()